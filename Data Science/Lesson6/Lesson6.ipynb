{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тема “Обучение с учителем”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "> 1. Импортируйте библиотеки pandas и numpy.\n",
    "> 2. Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. \n",
    "> 3. Создайте датафреймы X и y из этих данных. Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "> 4. Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "> 5. Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "> 6. Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Импортируйте библиотеки pandas и numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создайте датафреймы X и y из этих данных. Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузили датасет\n",
    "ds = load_boston(); \n",
    "\n",
    "# Загрузили датасет data в массив data, т.к. полный датасет содержит 2 массива data и  target\n",
    "#data = ds.data;\n",
    "# Загрузили датасет target в массив target\n",
    "#target = ds.target;\n",
    "# Загрузили список фич\n",
    "#feature_names = ds.feature_names;\n",
    "# Посмотреть колонки датасета ds.keys()\n",
    "# Посмотреть размерность датасета ds_data.shape\n",
    "# Список фич (признаков) ds.feature_names\n",
    "# Посмотреть массив ds_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Разобъем данные на датафреймы (тестовый и тренировочный)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(ds.data, columns = ds.feature_names);\n",
    "y = pd.DataFrame(ds.target, columns = ['target_price']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Загрузим класс для разбиения выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Разобьем датасеты на 2 выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Загрузим класс для линейной регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Создадим модель линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Посмотрим все признаки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM',\n",
       " 'ZN',\n",
       " 'INDUS',\n",
       " 'CHAS',\n",
       " 'NOX',\n",
       " 'RM',\n",
       " 'AGE',\n",
       " 'DIS',\n",
       " 'RAD',\n",
       " 'TAX',\n",
       " 'PTRATIO',\n",
       " 'B',\n",
       " 'LSTAT']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndarray.tolist(ds.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Обучение и тренировка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Посмотрим график и сравним точность для наших предсказаний.     \n",
    "Конвертируем некоторые отрицательные числа в положительные, т.к. это скорее всего ошибка. Используем функцию abs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['fivethirtyeight'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (14,5))\n",
    "\n",
    "pr = abs(pd.Series(predictions.flatten()).reset_index(drop = True))\n",
    "pr_min = pd.Series.min(pr)\n",
    "pr_max = pd.Series.max(pr)\n",
    "\n",
    "yt = abs(y_test['target_price'].reset_index(drop = True))\n",
    "yt_min = pd.Series.min(y_test['target_price'])\n",
    "yt_max = pd.Series.max(y_test['target_price'])\n",
    "\n",
    "\n",
    "plt.hist(\n",
    "    [np.clip(pr, pr_min, pr_max),\n",
    "     np.clip(yt, yt_min, yt_max),\n",
    "     ],\n",
    "    color = ['red', 'green'],\n",
    "    label = ['Predict', 'Test'],\n",
    "    density = True\n",
    ");\n",
    "plt.legend(loc = 'best');\n",
    "plt.xlabel('')\n",
    "fig.tight_layout();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>predict</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>28.648960</td>\n",
       "      <td>-5.048960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>36.495014</td>\n",
       "      <td>-4.095014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>15.411193</td>\n",
       "      <td>-1.811193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>25.403213</td>\n",
       "      <td>-2.603213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>18.855280</td>\n",
       "      <td>-2.755280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test    predict     error\n",
       "0  23.6  28.648960 -5.048960\n",
       "1  32.4  36.495014 -4.095014\n",
       "2  13.6  15.411193 -1.811193\n",
       "3  22.8  25.403213 -2.603213\n",
       "4  16.1  18.855280 -2.755280"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_pred = pd.DataFrame({'test':yt.reset_index(drop = True),'predict':pr})\n",
    "check_pred['error'] = yt - pr\n",
    "check_pred.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Вычислим среднеквадратичное отклонение руками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.028009782816454"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_manual = (check_pred['error']**2).mean()\n",
    "mse_manual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Импортируем mean_squared_error из модуля sklearn.metrics и вычислим его опять, чтобы проверить себя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.028009782816447"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_library = mean_squared_error(yt,pr)\n",
    "mse_library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вычислим  R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.731214900814652"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = r2_score(yt,pr)\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "> 1. Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "> 2. Сделайте агрумент n_estimators равным 1000, max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "> 3. Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0], чтобы получить из датафрейма одномерный массив Numpy,\n",
    "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
    "> 4. Сделайте предсказание на тестовых данных и посчитайте R2. \n",
    "> 5. Сравните с результатом из предыдущего задания.\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "##### Сделайте агрумент n_estimators равным 1000, max_depth должен быть равен 12 и random_state сделайте равным 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(max_depth=12, random_state=42, n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression, но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0], чтобы получить из датафрейма одномерный массив Numpy, так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = model.fit(X_train,  y_train.values[:, 0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сделайте предсказание на тестовых данных и посчитайте R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8691643189868505"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rfr.predict(X_test)\n",
    "\n",
    "t2 = r2_score(y_test,pred)\n",
    "\n",
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сравните с результатом из предыдущего задания. Напишите в комментариях к коду, какая модель в данном случае работает лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Точность модель 2 больше чем модели 1.\n",
      "Чем ближе показатель R² к единице тем выше наша точность и наоборот, чем ближе к нулю тем точность ниже.\n"
     ]
    }
   ],
   "source": [
    "if t1 > t2: \n",
    "    print ('Точность модель 1 больше чем модели 2');\n",
    "elif t1 < t2:\n",
    "    print ('\\nТочность модель 2 больше чем модели 1.');\n",
    "print('Чем ближе показатель R² к единице тем выше наша точность и наоборот, чем ближе к нулю тем точность ниже.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Задание 3\n",
    "> 1. Вызовите документацию для класса RandomForestRegressor, найдите информацию об атрибуте feature_importances_.\n",
    "> 2. С помощью этого атрибута найдите сумму всех показателей важности,установите, какие два признака показывают наибольшую важность.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вызовите документацию для класса RandomForestRegressor, найдите информацию об атрибуте feature_importances_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RandomForestRegressor.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_importances_ : array of shape = [n_features] \n",
      "The feature importances (the higher, the more important the feature).\n"
     ]
    }
   ],
   "source": [
    "print('feature_importances_ : array of shape = [n_features] \\nThe feature importances (the higher, the more important the feature).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### С помощью этого атрибута найдите сумму всех показателей важности,установите, какие два признака показывают наибольшую важность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Находим показатели и объединяем их со списком названий в словарь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CRIM': 0.0317789646134025,\n",
       " 'ZN': 0.001582418033436312,\n",
       " 'INDUS': 0.006462708683084199,\n",
       " 'CHAS': 0.001716301558637786,\n",
       " 'NOX': 0.01197879093255805,\n",
       " 'RM': 0.4397287873337629,\n",
       " 'AGE': 0.011604581592310375,\n",
       " 'DIS': 0.06602487727575124,\n",
       " 'RAD': 0.005048523874110854,\n",
       " 'TAX': 0.011670484018008027,\n",
       " 'PTRATIO': 0.020627175515947158,\n",
       " 'B': 0.011514663342870223,\n",
       " 'LSTAT': 0.3802617232261206}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict(zip(ds.feature_names,rfr.feature_importances_))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Выводим список наиболее важных показателей и их значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Наиболее важные показатели: [('RM', 0.4397287873337629), ('LSTAT', 0.3802617232261206)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import operator as o\n",
    "result = sorted(d.items(), key = o.itemgetter(1) , reverse = True)[:2];\n",
    "print ('\\nНаиболее важные показатели:', result,'\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4\n",
    "* В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection. \n",
    "* Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими.\n",
    "* Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "\n",
    "> 1. Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "> 2. Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "> 3. С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.\n",
    "> 4. Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.\n",
    "> 5. Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
    "pd.options.display.max_columns = 100.\n",
    "> 6. Просмотрите первые 10 строк датафрейма df.\n",
    "> 7. Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "> 8. Создайте объект Series под названием y из столбца Class.\n",
    "> 9. Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "> 10.Просмотрите информацию о их форме.\n",
    "> 11. Для поиска по сетке параметров задайте такие параметры:\n",
    "parameters = [{'n_estimators': [10, 15],\n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]\n",
    "> 12. Создайте модель GridSearchCV со следующими аргументами:\n",
    "estimator=RandomForestClassifier(random_state=100),\n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3.\n",
    "> 13. Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "> 14. Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "> 15. Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "> 16. Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. \n",
    "> 17. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "> 18. Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументовмассивы y_test и y_pred_proba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['fivethirtyeight'])\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Загрузите датасет creditcard.csv и создайте датафрейм df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_CSV = 'C:/Users/dmitriy.ivanov/Downloads/creditcard.csv'\n",
    "df = pd.read_csv(SOURCE_CSV)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class = pd.Series.value_counts(df['Class'].values, sort = False, dropna = False, normalize = True);\n",
    "df_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df).info == np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма: pd.options.display.max_columns = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Просмотрите первые 10 строк датафрейма df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создайте датафрейм X из датафрейма df, исключив столбец Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.loc[:,'Time':'Amount']\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создайте объект Series под названием y из столбца Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.Series(df['Class'])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X__train, X__test, y__train, y__test = train_test_split(X,y, test_size = 0.3, random_state = 100, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Для поиска по сетке параметров задайте такие параметры: parameters = [{'n_estimators': [10, 15], 'max_features': np.arange(3, 5), 'max_depth': np.arange(4, 7)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters =  [{'n_estimators': [10, 15], 'max_features': np.arange(3, 5), 'max_depth': np.arange(4, 7)}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создайте модель GridSearchCV со следующими аргументами: estimator=RandomForestClassifier(random_state=100), param_grid=parameters, scoring='roc_auc', cv=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV = GridSearchCV(estimator = RandomForestClassifier(random_state=100), \n",
    "                            param_grid = parameters, \n",
    "                            scoring = 'roc_auc', cv = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Обучите модель на тренировочном наборе данных (может занять несколько минут)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=100, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'n_estimators': [10, 15], 'max_features': array([3, 4]), 'max_depth': array([4, 5, 6])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearchCV.fit(X__train, y__train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Просмотрите параметры лучшей модели с помощью атрибута best_params_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}\n"
     ]
    }
   ],
   "source": [
    "print(GridSearchCV.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Предскажите вероятности классов с помощью полученнной модели и метода predict_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99717846e-01 2.82154033e-04]\n",
      " [9.99717846e-01 2.82154033e-04]\n",
      " [9.99717846e-01 2.82154033e-04]\n",
      " ...\n",
      " [9.99717846e-01 2.82154033e-04]\n",
      " [9.99717846e-01 2.82154033e-04]\n",
      " [9.99737336e-01 2.62663815e-04]]\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV.predict_proba(X__train)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00028215, 0.00028215, 0.00028215, ..., 0.00028215, 0.00028215,\n",
       "       0.00026266])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = gs[:,1]\n",
    "# или можно сделать тоже самое через датафрейм y_pred_proba = np.array(pd.DataFrame(gs)[1])\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Из модуля sklearn.metrics импортируйте метрику roc_auc_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1fdf077ba90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_proba,alpha= 0.4,label = 'Predict proba');\n",
    "plt.hist(y__test,alpha= 0.9, label = 'Test');\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Построим ROC - кривую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1,m2,m3 = roc_curve(y__train, y_pred_proba, pos_label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(m1,m2,color = 'red',linewidth = 1, label ='y__train')\n",
    "plt.plot([0,1],[0,1],color = 'blue',linestyle = '-.', linewidth = 0.5,markersize= 1);\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAUC_train = roc_auc_score(y__train, y_pred_proba);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV.fit(X__test, y__test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = GridSearchCV.predict_proba(X__test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_proba = gs1[:,1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAUC_test = roc_auc_score(y__test, y1_pred_proba);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестовые данные:\t 0.96098956245653 \n",
      "Тренировочные данные:\t 0.9703527882554751\n"
     ]
    }
   ],
   "source": [
    "print('Тестовые данные:\\t',RAUC_test,'\\nТренировочные данные:\\t',RAUC_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
